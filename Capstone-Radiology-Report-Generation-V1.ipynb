{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('D:/Capstone/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## Import Libraries here\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "import string\n",
    "import os\n",
    "import glob\n",
    "from time import time\n",
    "from keras import models\n",
    "from keras.applications import densenet\n",
    "import shutil\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Variables\n",
    "images_unzip_path = 'D:/Capstone/NLMCXR_png/'\n",
    "reports_unzip_path = 'D:/Capstone/NLMCXR_reports/'\n",
    "directory_in_str=reports_unzip_path+'/ecgen-radiology'\n",
    "pathlist = Path(directory_in_str).glob('**/*.xml')\n",
    "glove_dir = '/content/drive/My Drive/AIML/Capstone/Glove/'\n",
    "# Below path contains all the images\n",
    "images = images_unzip_path\n",
    "train_images = images_unzip_path\n",
    "proj_path = 'D:/Capstone/'\n",
    "chexnet_weights = '/content/drive/My Drive/AIML/Capstone/brucechou1983_CheXNet_Keras_0.3.0_weights.h5'\n",
    "para_pickle = proj_path+\"para.pickle\"\n",
    "first_sent_pickle = proj_path+\"first_sent.pickle\"\n",
    "word_vocab_pickle = proj_path+\"word_vocab.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the paragraph from findings\n",
    "with open(para_pickle, 'rb') as f:\n",
    "    para_findings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the first sentence from findings\n",
    "with open(first_sent_pickle, 'rb') as f:\n",
    "    first_sent_findings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the word vocab from findings\n",
    "with open(word_vocab_pickle, 'rb') as f:\n",
    "    word_vocab_findings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24288\n",
      "3668\n"
     ]
    }
   ],
   "source": [
    "# Create a list of all the training captions for Findings\n",
    "all_para_findings = []\n",
    "for key, val in para_findings.items():\n",
    "    for cap in val:\n",
    "        all_para_findings.append(cap)\n",
    "print(len(all_para_findings))\n",
    "\n",
    "all_first_sent_findings = []\n",
    "for key, val in first_sent_findings.items():\n",
    "    for cap in val:\n",
    "        all_first_sent_findings.append(cap)\n",
    "print(len(all_first_sent_findings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed findings words 2145 -> 2145\n"
     ]
    }
   ],
   "source": [
    "# Build Word Vocab\n",
    "word_count_threshold = 1\n",
    "findings_word_counts = {}\n",
    "\n",
    "nsents = 0\n",
    "for sent in all_para_findings:\n",
    "    nsents += 1\n",
    "    for w in sent.split(' '):\n",
    "        findings_word_counts[w] = findings_word_counts.get(w, 0) + 1\n",
    "\n",
    "findings_w_vocab = [w for w in findings_word_counts if findings_word_counts[w] >= word_count_threshold]\n",
    "print('preprocessed findings words %d -> %d' % (len(findings_word_counts), len(findings_w_vocab)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ixtoword = {}\n",
    "wordtoix = {}\n",
    "\n",
    "\n",
    "ix = 1\n",
    "for w in findings_w_vocab:\n",
    "    wordtoix[w] = ix\n",
    "    ixtoword[ix] = w\n",
    "    ix += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2146\n"
     ]
    }
   ],
   "source": [
    "findings_vocab_size = len(ixtoword) + 1 # one for appended 0's\n",
    "print(findings_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Findings Description Length: 50\n"
     ]
    }
   ],
   "source": [
    "# convert a dictionary of clean descriptions to a list of descriptions\n",
    "def to_lines(descriptions):\n",
    "\tall_desc = list()\n",
    "\tfor key in descriptions.keys():\n",
    "\t\t[all_desc.append(d) for d in descriptions[key]]\n",
    "\treturn all_desc\n",
    "\n",
    "# calculate the length of the description with the most words\n",
    "def max_length(descriptions):\n",
    "\tlines = to_lines(descriptions)\n",
    "\treturn max(len(d.split()) for d in lines)\n",
    "\n",
    "# determine the maximum sequence length\n",
    "findings_max_length = max_length(para_findings)\n",
    "print('Findings Description Length: %d' % findings_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
